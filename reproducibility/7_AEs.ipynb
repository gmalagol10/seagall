{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a843f-7edb-4d90-9e34-9dcb1a251be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import brokenaxes\n",
    "from brokenaxes import brokenaxes as brokax\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import sklearn\n",
    "import uncertainties\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import string\n",
    "import grae\n",
    "import collections\n",
    "import time\n",
    "from grae.models import GRAE\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import Utils as ut\n",
    "import Models as mod\n",
    "%matplotlib inline\n",
    "\n",
    "AEs=[\"scVI\",\"TopoAE\",\"VAE\",\"PeakVI\",\"GRAE\",\"pca\"]\n",
    "AEs_order=[\"GRAE\",\"TopoAE\",\"VAE\",\"PeakVI\",\"scVI\",\"pca\"]\n",
    "new_colors=ut.colors_to_use_pastel[:5] + [ut.colors_to_use_pastel[8]]\n",
    "palette = {AEs[i] : new_colors[i] for i in range(len(AEs))} \n",
    "palette = collections.OrderedDict((k, palette[k]) for k in AEs_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d2c83-f82b-4702-9dea-daee40ae391f",
   "metadata": {},
   "source": [
    "Replace the folders path with the appropriate ones of your machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d220a5-51b6-40fc-8b6d-77e4b796df3d",
   "metadata": {},
   "source": [
    "# Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e29d59-4b69-4e9f-b0fc-eed4d16c1309",
   "metadata": {},
   "source": [
    "## CMs and Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da862da-dbcb-4e87-b4f7-424d96e4ce9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets=[\"10XhsBrain3kMO\", \"10XhsBrain3kMO\",\"Kidney\", \"10XhsPBMC10kMO\",\"10XhsPBMC10kMO\", \"MouseBrain\"]\n",
    "featurespaces=[\"Peak\",\"GEX\",\"Peak\", \"Peak\", \"GEX\", \"Peak\"]\n",
    "jobs=[\"BrP\", \"BrG\", \"KiP\", \"PbP\", \"PbG\", \"MbP\"]\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    print(dataset, featurespace)\n",
    "    adata=sc.read_h5ad(f\"Datasets/{dataset}/FeatureSpaces/{featurespace}/CM/{dataset}_{featurespace}_QC.h5ad\")\n",
    "    for d in np.linspace(0, 50, 11).astype(int):\n",
    "        print(d)\n",
    "        for run in range(0, 10):\n",
    "            m = torch.nn.Dropout(p=d/100)\n",
    "            inp = torch.tensor(adata.X.todense())\n",
    "            output = m(inp)\n",
    "            adata.layers[f\"X_{str(d)}_{str(run)}\"]=scipy.sparse.csr_matrix(output)\n",
    "    adata.write(f\"Datasets/{dataset}/FeatureSpaces/{featurespace}/CM/{dataset}_{featurespace}_Dropout.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c918053-03d2-41bc-b67f-e462faa4ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\"10XhsBrain3kMO\", \"10XhsBrain3kMO\",\"Kidney\", \"10XhsPBMC10kMO\",\"10XhsPBMC10kMO\", \"MouseBrain\"]\n",
    "featurespaces=[\"Peak\",\"GEX\",\"Peak\", \"Peak\", \"GEX\", \"Peak\"]\n",
    "jobs=[\"BrP\", \"BrG\", \"KiP\", \"PbP\", \"PbG\", \"MbP\"]\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    print(dataset, featurespace, job)\n",
    "    if featurespace == \"GEX\":\n",
    "        table = \"Tables/AEsGEX.tsv\"\n",
    "    elif featurespace == \"Peak\":\n",
    "        table = \"Tables/AEsPeak.tsv\"\n",
    "    os.system(f\"sbatch Run_Exp.sh Robustness VAE {dataset} {featurespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed20fc-e304-4a9f-8f91-464c55521998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a578a-a64a-4c1d-8f34-25433c27d583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5efd-3d3f-4e47-a182-229a150e6379",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb27f30-eb96-4bb7-a883-a2cd01061a12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets=[\"10XhsBrain3kMO\", \"10XhsBrain3kMO\",\"Kidney\", \"10XhsPBMC10kMO\",\"10XhsPBMC10kMO\", \"MouseBrain\"]\n",
    "featurespaces=[\"Peak\",\"GEX\",\"Peak\", \"Peak\", \"GEX\", \"Peak\"]\n",
    "jobs=[\"BrP\", \"BrG\", \"KiP\", \"PbP\", \"PbG\", \"MbP\"]\n",
    "df=pd.DataFrame(columns=[\"Dataset\",\"FS\",\"AE\",\"Dropout\",\"MSE\",\"Run\"])\n",
    "for dataset, fs, job in zip(datasets, featurespaces, jobs):\n",
    "    adata=sc.read_h5ad(f\"Datasets/{dataset}/FeatureSpaces/{fs}/CM/{dataset}_{fs}_QC.h5ad\")\n",
    "    for run in range(0, 10):\n",
    "        for dp in np.linspace(0, 50, 6).astype(int):\n",
    "            AE=\"VAE\"\n",
    "            model_name=f\"Datasets/{dataset}/FeatureSpaces/{fs}/Dropout/VAE/{dataset}_{fs}_VAE_{dp}_{run}.pth\"\n",
    "            if os.path.isfile(model_name):\n",
    "                print(f\"Run {run}/10 and dropout {dp}\", time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()), \"AE is --> \", AE,  flush=True)\n",
    "                ae_kwargs={}\n",
    "                ae_kwargs[\"hidden_dim\"]=int(adata.shape[1]**(1/2))\n",
    "                ae_kwargs[\"latent_dim\"]=int(adata.shape[1]**(1/3))\n",
    "                ae_kwargs[\"input_dim\"]=adata.shape[1]\n",
    "                data = torch.tensor(adata.X.toarray(), dtype=torch.float32)\n",
    "                model = mod.VAutoencoder(ae_kwargs=ae_kwargs)\n",
    "                model.load_state_dict(torch.load(model_name))\n",
    "            \n",
    "                mse=sklearn.metrics.mean_squared_error(adata.X.toarray(), model.decode(model.encode(data)[0]).detach().numpy())\n",
    "                \n",
    "                d=pd.DataFrame(data=np.array([dataset, fs, AE, dp, mse, run]).T, index=df.columns).T\n",
    "                df=pd.concat([df,d])\n",
    "\n",
    "            AE=\"TopoAE\"\n",
    "            model_name=f\"Datasets/{dataset}/FeatureSpaces/{fs}/Dropout/TopoAE/{dataset}_{fs}_TopoAE_{dp}_{run}.pth\"\n",
    "            if os.path.isfile(model_name):\n",
    "                print(f\"Run {run}/10 and dropout {dp}\", time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()), \"AE is --> \", AE,  flush=True)\n",
    "                data = torch.tensor(adata.X.toarray(), dtype=torch.float32)\n",
    "                ae_kwargs={\"input_dim\" : adata.shape[1],  \"hidden_dim\" : int(adata.shape[1]**(1/2)), \"latent_dim\" : int(adata.shape[1]**(1/3))}\n",
    "                model = mod.TopologicallyRegularizedAutoencoder(ae_kwargs=ae_kwargs)\n",
    "                model.load_state_dict(torch.load(model_name))\n",
    "            \n",
    "                mse=sklearn.metrics.mean_squared_error(adata.X.toarray(), model.decode(model.encode(data)).detach().numpy())\n",
    "                \n",
    "                d=pd.DataFrame(data=np.array([dataset, fs, AE, dp, mse, run]).T, index=df.columns).T\n",
    "                df=pd.concat([df,d])\n",
    "    \n",
    "            AE=\"GRAE\"\n",
    "            model_name=f\"Datasets/{dataset}/FeatureSpaces/{fs}/Dropout/GRAE/{dataset}_{fs}_GRAE_{dp}_{run}.pth\"\n",
    "            if os.path.isfile(model_name):\n",
    "                print(f\"Run {run}/10 and dropout {dp}\", time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()), \"AE is --> \", AE,  flush=True)\n",
    "                model = GRAE(n_components=int(adata.shape[1]**(1/3)))\n",
    "                model.load(model_name)\n",
    "    \n",
    "                data=grae.data.base_dataset.BaseDataset(adata.X.toarray(), np.ones(adata.shape[0]), \"none\", 0.85, 42, np.ones(adata.X.shape[0]))\n",
    "                \n",
    "                mse=sklearn.metrics.mean_squared_error(adata.X.toarray(), model.inverse_transform(model.transform(data)))\n",
    "            \n",
    "                d=pd.DataFrame(data=np.array([dataset, fs, AE, dp, mse, run]).T, index=df.columns).T\n",
    "                df=pd.concat([df,d])\n",
    "    \n",
    "            if fs == \"GEX\":\n",
    "                AE=\"scVI\"\n",
    "                path=f\"Datasets/{dataset}/FeatureSpaces/{fs}/Dropout/scVI/{dataset}_{fs}_scVI_{dp}_{run}\"\n",
    "                model_name=f\"{path}/model.pt\"         \n",
    "                if os.path.isfile(model_name):\n",
    "                    print(f\"Run {run}/10 and dropout {dp}\", time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()), \"AE is --> \", AE,  flush=True)\n",
    "                    scvi.model.LinearSCVI.setup_anndata(adata=adata)\n",
    "                    model = scvi.model.LinearSCVI(adata=adata)\n",
    "                    model.load(path, adata=adata)\n",
    "                    model.is_trained=True\n",
    "        \n",
    "                    mse=sklearn.metrics.mean_squared_error(adata.X.toarray(), model.get_normalized_expression(n_samples=1))\n",
    "        \n",
    "                    d=pd.DataFrame(data=np.array([dataset, fs, AE, dp, mse, run]).T, index=df.columns).T\n",
    "                    df=pd.concat([df,d])\n",
    "            else:\n",
    "                AE=\"PeakVI\"\n",
    "                path=f\"Datasets/{dataset}/FeatureSpaces/{fs}/Dropout/PeakVI/{dataset}_{fs}_PeakVI_{dp}_{run}\"\n",
    "                model_name=f\"{path}/model.pt\"         \n",
    "                if os.path.isfile(model_name):\n",
    "                    print(f\"Run {run}/10 and dropout {dp}\", time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.localtime()), \"AE is --> \", AE,  flush=True)\n",
    "                    scvi.model.PEAKVI.setup_anndata(adata=adata)\n",
    "                    model = scvi.model.PEAKVI(adata=adata)\n",
    "                    model.load(path, adata=adata)\n",
    "                    model.is_trained=True\n",
    "        \n",
    "                    mse=sklearn.metrics.mean_squared_error(adata.X.toarray(), model.get_accessibility_estimates())\n",
    "        \n",
    "                    d=pd.DataFrame(data=np.array([dataset, fs, AE, dp, mse, run]).T, index=df.columns).T\n",
    "                    df=pd.concat([df,d])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(\"index\", axis=1, inplace=True)\n",
    "df.to_csv(\"Tables/Robustness.tsv.gz\", sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954518e-4c72-40bd-ab80-41b515d79090",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0, 50, 6).astype(int)/100\n",
    "xticks=[0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "sps1, sps2 = GridSpec(2,1)\n",
    "params = {'axes.labelsize': 20,\n",
    "         'axes.titlesize': 20,\n",
    "         'xtick.labelsize' : 15,\n",
    "         'ytick.labelsize': 15,\n",
    "         \"lines.linewidth\" : 4,\n",
    "         \"figure.dpi\" : 300,\n",
    "         \"figure.figsize\": [18, 10]}\n",
    "plt.rcParams.update(params)\n",
    "fig = plt.figure()\n",
    "\n",
    "gs = GridSpec(2,3, wspace=0.5, hspace=0.6)\n",
    "spss = {f\"sps{i}\" : sp for i, sp in enumerate(gs)}\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax5 = fig.add_subplot(gs[0, 2])\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "xticks=[0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "i=0\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    d=df[(df[\"Dataset\"]==dataset) & (df[\"FS\"]==featurespace)]\n",
    "    if \"PeakVI\" in set(d[\"AE\"]):\n",
    "        y_breaks=((0.0062, 0.021), (0.255,0.263))\n",
    "    else:\n",
    "        y_breaks=None\n",
    "    bax = brokax(ylims=y_breaks, hspace=0.3, subplot_spec=spss[f\"sps{i}\"])\n",
    "    for AE in AEs_order:\n",
    "        if AE in list(set(d[\"AE\"])):\n",
    "            d_ae=d[d[\"AE\"]==AE].copy()\n",
    "            y=d_ae.groupby(\"Dropout\")[\"MSE\"].mean()\n",
    "            yerr=3*d_ae.groupby(\"Dropout\")[\"MSE\"].sem()\n",
    "            bax.errorbar(x=x, y=y, yerr=yerr, ecolor=palette[AE], elinewidth=10, marker=\"o\", c=palette[AE])  \n",
    "    if \"PeakVI\" in set(d[\"AE\"]):      \n",
    "        bax.axs[1].set_xticks(xticks, xticks)   \n",
    "    else:\n",
    "        bax.axs[0].set_xticks(xticks, xticks)   \n",
    "\n",
    "    if \"PeakVI\" not in set(d[\"AE\"]):\n",
    "        bax.axs[0].set_ylim([0.01, 0.05])\n",
    "        yticks=[0.015, 0.025, 0.045]\n",
    "        bax.axs[0].set_yticks(yticks, yticks)\n",
    "    bax.spines['top'][0].set_visible(False)\n",
    "    bax.spines['right'][0].set_visible(False)\n",
    "    try:\n",
    "        bax.axs[0].set_xlabel('', rotation=0, labelpad=10)\n",
    "        bax.axs[0].set_ylabel('', rotation=90, labelpad=10)\n",
    "    except:\n",
    "        bax.set_xlabel('', rotation=0, labelpad=10)\n",
    "        bax.set_ylabel('', rotation=90, labelpad=10)\n",
    "    bax.set_title(f\"{dataset}\\n{featurespace}\\n\", loc='left', y=0.975, size=17)\n",
    "    i+=1\n",
    "    \n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([], [])\n",
    "    ax.set_xlabel('Dropout', rotation=0, labelpad=30)\n",
    "    ax.set_ylabel('MSE', rotation=90, labelpad=60)\n",
    "handles=[]\n",
    "for key in AEs_order:\n",
    "    handles.append(mpatches.Patch(color=palette[key], label=key))\n",
    "ax5.legend(bbox_to_anchor=(1.67, 0.2), title=\"Method\", fontsize=17, title_fontsize=20, handles=handles)\n",
    "for i, ax in enumerate([ax1, ax2, ax5, ax3, ax4, ax6]):\n",
    "    ax.text(-0.1, 1.075, string.ascii_uppercase[i], transform=ax.transAxes, size=20, weight='bold',rotation=0)    \n",
    "\n",
    "plt.savefig(f\"Figures/Figure2.png\", format=\"png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21071896-a988-4709-8d02-0c2828d84c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a9e24ee-f031-44eb-bad1-0fd13c751dd3",
   "metadata": {},
   "source": [
    "# Homogeineity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87fdcd-f1e7-4923-9f1d-246582044d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\"10XhsBrain3kMO\", \"10XhsBrain3kMO\",\"Kidney\", \"10XhsPBMC10kMO\",\"10XhsPBMC10kMO\", \"MouseBrain\"]\n",
    "featurespaces=[\"Peak\",\"GEX\",\"Peak\", \"Peak\", \"GEX\", \"Peak\"]\n",
    "jobs=[\"BrP\", \"BrG\", \"KiP\", \"PbP\", \"PbG\", \"MbP\"]\n",
    "adatas={}\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    print(dataset, featurespace)\n",
    "    adatas[job]=sc.read_h5ad(f\"Datasets/{dataset}/FeatureSpaces/{featurespace}/CM/{dataset}_{featurespace}_MS.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebca053-e46e-47c0-9387-d95beb0dae8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"Dataset\",\"FS\",\"Method\",\"AbsoluteHetero\",\"NN\",\"N_CT\"])\n",
    "for dataset, featurespace, key in zip(datasets, featurespaces, jobs):\n",
    "    n_ct=len(set(adatas[key].obs.CellType.dropna()))\n",
    "    for graph in adatas[key].obsp.keys():\n",
    "        print(key, graph)\n",
    "        for a in adatas[key].obsp[graph].toarray():\n",
    "            b=[True if el>0 else False for el in a]\n",
    "            d=adatas[key].obs.loc[b].copy()\n",
    "            subd=pd.DataFrame(index=df.columns, data=[dataset, featurespace, graph, len(set(d[\"CellType\"])), len(d), n_ct]).T\n",
    "            df=pd.concat([df,subd], axis=0)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(\"index\", axis=1, inplace=True)\n",
    "df.to_csv(\"Tables/Heteorgeneity.tsv.gz\", sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cfbc92-a850-4a0d-84e2-9228949d02b9",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194d377-9927-4a86-b23d-a2b7f2c51fbd",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ccf09-5a10-4530-a833-3a2fff3d2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Tables/Robustness.tsv.gz\", sep=\"\\t\", index_col=0)\n",
    "datasets=[\"Kidney\",\"Human brain\",\"Human brain\", \"Mouse brain\", \"PBMC\",\"PBMC\"]\n",
    "featurespaces=[\"Peaks\",\"Peaks\", \"GEX\", \"Peaks\", \"Peaks\", \"GEX\"]\n",
    "jobs=[\"BrP\", \"BrG\", \"KiP\", \"PbP\", \"PbG\", \"MbP\"]\n",
    "\n",
    "df[\"FS\"]=df[\"FS\"].replace(\"Peak\",\"Peaks\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"10XhsBrain3kMO\",\"Human brain\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"10XhsPBMC10kMO\",\"PBMC\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"MouseBrain\",\"Mouse brain\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10497202-f14d-4de9-a64e-39440fc1b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0, 50, 6).astype(int)/100\n",
    "xticks=[0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "sps1, sps2 = GridSpec(2,1)\n",
    "params = {'axes.labelsize': 20,\n",
    "         'axes.titlesize': 20,\n",
    "         'xtick.labelsize' : 15,\n",
    "         'ytick.labelsize': 15,\n",
    "         \"lines.linewidth\" : 4,\n",
    "         \"figure.dpi\" : 300,\n",
    "         \"figure.figsize\": [19, 10]}\n",
    "plt.rcParams.update(params)\n",
    "fig = plt.figure()\n",
    "\n",
    "gs = GridSpec(2,3, wspace=0.5, hspace=0.6)\n",
    "spss = {f\"sps{i}\" : sp for i, sp in enumerate(gs)}\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax5 = fig.add_subplot(gs[0, 2])\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "xticks=[0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "i=0\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    d=df[(df[\"Dataset\"]==dataset) & (df[\"FS\"]==featurespace)]\n",
    "    if \"PeakVI\" in set(d[\"AE\"]):\n",
    "        y_breaks=((0.0062, 0.021), (0.255,0.263))\n",
    "    else:\n",
    "        y_breaks=None\n",
    "    bax = brokax(ylims=y_breaks, hspace=0.3, subplot_spec=spss[f\"sps{i}\"])\n",
    "    for AE in AEs_order:\n",
    "        if AE in list(set(d[\"AE\"])):\n",
    "            d_ae=d[d[\"AE\"]==AE].copy()\n",
    "            y=d_ae.groupby(\"Dropout\")[\"MSE\"].mean()\n",
    "            yerr=3*d_ae.groupby(\"Dropout\")[\"MSE\"].sem()\n",
    "            bax.errorbar(x=x, y=y, yerr=yerr, ecolor=palette[AE], elinewidth=10, marker=\"o\", c=palette[AE])  \n",
    "    if \"PeakVI\" in set(d[\"AE\"]):      \n",
    "        bax.axs[1].set_xticks(xticks, xticks)   \n",
    "    else:\n",
    "        bax.axs[0].set_xticks(xticks, xticks)   \n",
    "\n",
    "    if \"PeakVI\" not in set(d[\"AE\"]):\n",
    "        bax.axs[0].set_ylim([0.01, 0.05])\n",
    "        yticks=[0.015, 0.025, 0.045]\n",
    "        bax.axs[0].set_yticks(yticks, yticks)\n",
    "    bax.spines['top'][0].set_visible(False)\n",
    "    bax.spines['right'][0].set_visible(False)\n",
    "    try:\n",
    "        bax.axs[0].set_xlabel('', rotation=0, labelpad=10)\n",
    "        bax.axs[0].set_ylabel('', rotation=90, labelpad=10)\n",
    "    except:\n",
    "        bax.set_xlabel('', rotation=0, labelpad=10)\n",
    "        bax.set_ylabel('', rotation=90, labelpad=10)\n",
    "    bax.set_title(f\"    {dataset} {featurespace}\\n\", loc='center', size=17)\n",
    "    i+=1\n",
    "    \n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([], [])\n",
    "    ax.set_xlabel('Dropout', rotation=0, labelpad=30)\n",
    "    ax.set_ylabel('MSE', rotation=90, labelpad=60)\n",
    "handles=[]\n",
    "for key in AEs_order:\n",
    "    handles.append(mpatches.Patch(color=palette[key], label=key))\n",
    "ax5.legend(bbox_to_anchor=(1.67, 0.2), title=\"Method\", fontsize=17, title_fontsize=20, handles=handles)\n",
    "for i, ax in enumerate([ax1, ax2, ax5, ax3, ax4, ax6]):\n",
    "    ax.text(-0.1, 1.075, string.ascii_uppercase[i+1], transform=ax.transAxes, size=20, weight='bold',rotation=0)    \n",
    "\n",
    "plt.savefig(f\"Figures/Figure2.png\", format=\"png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b730f-37df-4680-a76e-005fa76226e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c680919-6277-4113-b49e-3b910f4057ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e46f4300-862a-403e-a7b9-9608004187e0",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b705f-fae9-46ef-93a3-4ad1b0aae1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Tables/Heteorgeneity.tsv.gz\", sep=\"\\t\", index_col=0)\n",
    "df[\"Heteorgeneity\"]=np.array(df[\"AbsoluteHetero\"]/(df[\"NN\"]*df[\"N_CT\"]))\n",
    "df[\"Homogeneity\"]=1-df[\"Heteorgeneity\"]\n",
    "df[\"Method\"]=df[\"Method\"].str.replace(\"_kNN\",\"\")\n",
    "print(df.shape)\n",
    "df[\"FS\"]=df[\"FS\"].replace(\"Peak\",\"Peaks\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"10XhsBrain3kMO\",\"Human brain\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"10XhsPBMC10kMO\",\"PBMC\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"MouseBrain\",\"Mouse brain\")\n",
    "df[\"Dataset\"]=df[\"Dataset\"].replace(\"Kidney\",\"Kidney\")\n",
    "datasets=[\"Kidney\",\"Human brain\",\"Human brain\", \"Mouse brain\", \"PBMC\",\"PBMC\"]\n",
    "featurespaces=[\"Peaks\",\"Peaks\", \"GEX\", \"Peaks\", \"Peaks\", \"GEX\"]\n",
    "jobs=[\"BrP\", \"BrG\", \"KiP\", \"PbP\", \"PbG\", \"MbP\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ada93b-a999-492b-af6f-512103725cf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae_order=[\"GRAE\",\"TopoAE\",\"VAE\",\"PeakVI\",\"scVI\",\"pca\"]\n",
    "col_order=['Kidney+Peaks', 'Human brain+Peaks', 'Human brain+GEX', 'Mouse brain+Peaks', 'PBMC+Peaks','PBMC+GEX']\n",
    "\n",
    "d=pd.DataFrame()\n",
    "metric=\"Homogeneity\"\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    print(dataset, featurespace)\n",
    "    t=df[(df[\"Dataset\"]==dataset) & (df[\"FS\"]==featurespace)]\n",
    "    aes=t[[metric,\"Method\"]].groupby(\"Method\")[metric].mean().index\n",
    "    mean=np.array(t[[metric,\"Method\"]].dropna().groupby(\"Method\")[metric].mean())\n",
    "    sem=np.array(3*t[[metric,\"Method\"]].dropna().groupby(\"Method\")[metric].sem())\n",
    "    for ae, m, s in zip(aes, mean, sem):\n",
    "        d=pd.concat([d, pd.DataFrame([f\"{dataset}+{featurespace}\", ae, str(uncertainties.ufloat(m, s))], index=[\"Ds&Fs\", \"DR method\", \"Mean +- 3*SEM\"]).T], axis=0)\n",
    "defd=d.pivot(index=\"DR method\", columns=\"Ds&Fs\", values=\"Mean +- 3*SEM\")[col_order].loc[ae_order]\n",
    "for col in defd.columns:\n",
    "    defd[col]=defd[col].str.replace(\"+/-\",u\"\\u00B1\")\n",
    "defd.to_csv(\"Tables/TableHomogeneity.tsv\", sep=\"\\t\", columns=None)\n",
    "defd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d2b91-9d5a-45a6-bd66-e23958d5cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'axes.labelsize': 20,\n",
    "         'axes.titlesize': 20,\n",
    "         'xtick.labelsize' : 15,\n",
    "         'ytick.labelsize': 15,\n",
    "         \"lines.linewidth\" : 4,\n",
    "         \"figure.dpi\" : 300,\n",
    "         \"figure.figsize\": [18, 10]}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "fig, axs = plt.subplots(2,3)\n",
    "axs=axs.flatten()\n",
    "i=0\n",
    "for dataset, featurespace, job in zip(datasets, featurespaces, jobs):\n",
    "    d=df[(df[\"Dataset\"]==dataset) & (df[\"FS\"]==featurespace)]  \n",
    "    order=[ae for ae in AEs_order if ae in set(d[\"Method\"])]\n",
    "    colors=[palette[ae] for ae in order]\n",
    "    means=np.array(d.groupby(\"Method\")[\"Homogeneity\"].mean().loc[order])\n",
    "    sems=5*np.array(d.groupby(\"Method\")[\"Homogeneity\"].sem().loc[order])\n",
    "    axs[i].bar(x=order, height=means, yerr=sems, edgecolor=colors, facecolor=colors, capsize=10, ecolor=\"black\", linewidth=5, alpha=0.75, width=0.8)\n",
    "    axs[i].set_ylim([0.95, 1])\n",
    "    axs[i].set_title(f\"{dataset} {featurespace}\\n\", loc='center', size=17)\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].spines['right'].set_visible(False)    \n",
    "    axs[i].text(-0.2, 1.15, string.ascii_uppercase[i+1], transform=axs[i].transAxes, size=20, weight='bold',rotation=0)    \n",
    "    axs[i].set_xlabel('Method', rotation=0, labelpad=10)\n",
    "    axs[i].set_ylabel('Homogeneity', rotation=90, labelpad=10)\n",
    "    i+=1    \n",
    "\n",
    "fig.tight_layout(h_pad=3, w_pad=2)\n",
    "plt.savefig(\"Figures/Figure3.png\", format=\"png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0e41f-53e9-4ee2-acc7-c8e98f2ac081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050029c-c839-40bd-8f20-b9c3591b19f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a300f89-1a5b-4163-bde3-1c4abcc063c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "444.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
